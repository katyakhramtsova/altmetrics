---
title: "on the origins of citations"
author: "katya"
date: "Tuesday, September 15, 2015"
output:
  pdf_document:
    toc: yes
  html_document:
    fig_caption: yes
    fig_height: 8
    fig_width: 8
    highlight: espresso
    number_sections: yes
    self_contained: no
    theme: cerulean
    toc: yes
  word_document: default
---

# Load the data

## using read.delim

```{r load_data}
counts_raw <- read.delim("data/counts-raw.txt.gz")
counts_norm <- read.delim("data/counts-norm.txt.gz")
```

# Data exploration

What's the distribution of authors in all articles of our data set?
```{r author_hist, fig.cap="Figure 1: Number of Authors per Article", echo=FALSE}
hist(counts_raw$authorsCount, main="Authors per paper", xlab="# authors", ylab="frequency")
```

```{r facebook_hist, fig.cap="Figure 2: Number of Facebook Shares per Article", echo=FALSE}
hist(counts_raw$facebookShareCount, main="Facebook shares per paper", xlab="# shares", ylab="frequency")
```

The average number of Facebook shares per paper in the data set is `r mean(counts_raw$facebookShareCount)[1]`

##dplyr

```{r}
library("dplyr")
```

```{r}
research <- filter(counts_raw, articleType == "Research Article")
```

```{r}
research_2006 <- filter(research, year == 2006)
nrow(research_2006)
```

```{r}
research_2006_tweet <- filter(research_2006, backtweetsCount > 0)
nrow(research_2006_tweet)
```

```{r}
research_2006_fb <- filter(research, year == 2006,
                           facebookCommentCount > 0)
nrow(research_2006_fb)
```

```{r}
research_2006_fb_tweet <- filter(research, year == 2006,
                                 facebookCommentCount > 0 |
                                 backtweetsCount > 0)
nrow(research_2006_fb_tweet)
```

```{r}
research_2006_fb_tweet_disease <- filter(research, year == 2006,
                                         facebookCommentCount > 0 |
                                         backtweetsCount > 0,
                                         grepl("Infectious Diseases",
                                               plosSubjectTags))
nrow(research_2006_fb_tweet_disease)
```

```{r}
colnames(research)
```

```{r}
article_info <- select(research, doi, pubDate, journal, title,
                       articleType, authorsCount)
colnames(article_info)
```

```{r}
article_info <- select(research, doi:authorsCount)
colnames(article_info)
```

```{r}
metrics <- select(research, contains("Count"))
colnames(metrics)
```

```{r}
metrics <- select(research, contains("Count"), -authorsCount)
colnames(metrics)
```

```{r}
metrics <- select(research, contains("Count"), -authorsCount,
                  f1000Factor, wikipediaCites)
colnames(metrics)
```

```{r}
head(select(research, journal))
head(select(research, 3))
```

```{r}
slice(article_info, 1:3)
```


```{r}
low_cite <- filter(research, year <= 2008,pdfDownloadsCount >  1000, mendeleyReadersCount > 15, wosCountThru2011 < 10)
length(low_cite)
```


```{r}
low_cite <- filter(research, year <= 2008, pdfDownloadsCount >  1000, mendeleyReadersCount > 15, wosCountThru2011 < 10)
nrow(low_cite)
length(low_cite)
select(low_cite, title)
```

### Chaining commands with dplyr

pipe character %>%

```{r}
facebook_2006 <- research %>% filter(year == 2006) %>%
  select(contains("facebook"))
head(facebook_2006)

research %>% filter(year == 2006) %>%
  select(contains("facebook")) %>% nrow
```

arrange, work similar to function order
```{r}
research %>%
  arrange(authorsCount, wosCountThru2011) %>%
  select(authorsCount, wosCountThru2011) %>%
  slice(1:10)
```

```{r}
research %>%
  arrange(desc(authorsCount), desc(wosCountThru2011)) %>%
  select(authorsCount, wosCountThru2011) %>%
  slice(1:10)
```

Using a chain of pipes, output the titles of the three research articles with the largest 2011 citation count.
```{r, Title of most cited articles}
research %>% arrange(desc(authorsCount), desc(wosCountThru2011), desc(title))  %>% select(title) %>% slice(1:3)
```
Correct solution solution
```{r}
reseach %>% arrange(desc(wosCountThru2011)) %>% slice(1:3) %>% select(title)
```


Using a chain of pipes, output the author count, title, journal, and subject tags (plosSubjectTags) of the three research articles with the largest number of authors.
```{r, Lots of authors}
research %>% arrange(desc(authorsCount), desc(title), desc(journal), desc(plosSubjectTags))  %>% select(authorsCount, title, journal, plosSubjectTags) %>% slice(1:3)
```
Correct solution solution
```{r}
research %>% arrange(desc(authorCount)) %>% select(authorsCount, title, journal, plosSubjectTags) %>% slice(1:3) 
```

###summarizing with dplyr

```{r}
research <- mutate(research,
                   weeksSincePublished = daysSincePublished / 7,
                   yearsSincePublished = weeksSincePublished / 52)
select(research, contains("Since")) %>% slice(1:10)
research %>% select(contains("Since")) %>% slice(1:10)
```

using summarize

```{r}
research %>% summarize(research, plos_mean = mean(plosCommentCount))
```

```{r}
research %>% group_by(journal, year) %>% summarize(tweets_mean = mean(backtweetsCount))
```

Create a new data frame, tweets_per_journal, that for each journal contains the total number of articles, the mean number of tweets received by articles in that journal, and the standard error of the mean (SEM) of the number of tweets. The SEM is the standard deviation divided by the square root of the sample size (i.e. the number of articles).

```{r Summarizing the number of tweets per journal}
tweets_per_journal <- group_by(journal) %>% summarize(num_articles= , tweets_mean = mean(backtweetsCount), SEM = (stdev(backtweetsCount))/sqrt(num_articles))
```
Correct answer
```{r}
tweets_per_journal <- research %>% group_by(journal) %>% summarize(num= n() , mean = mean(backtweetsCount), sem = (sd(backtweetsCount))/sqrt(num))
```

#ggplot

```{r}
library("ggplot")
```

```{r}
p <- ggplot(data = research, mapping = aes(x = pdfDownloadsCount,
                                           y = wosCountThru2011)) + 
  geom_point(aes(color = journal))
p
```

```{r}
p <- ggplot(research, aes(x = pdfDownloadsCount,
                          y = wosCountThru2011)) +
  geom_point(aes(size = authorsCount))
p
```

```{r}
p <- ggplot(research, aes(x = pdfDownloadsCount,
                          y = wosCountThru2011)) +
  geom_point(aes(alpha = daysSincePublished))
p
```

```{r}
p <- ggplot(research, aes(x = pdfDownloadsCount,
                          y = wosCountThru2011)) +
  geom_point(aes(color = journal)) +
  geom_smooth()
p
```

Create a scatter plot with daysSincePublished mapped to the x-axis and wosCountThru2011 mapped to the y-axis. Include a loess fit of the data. Set the transparency level (alpha) of the points to 0.5 and color the points according to the journal where the article was published. Make the loess curve red.
```{r}
p <- ggplot(research, aes(x = daysSincePublished,
                          y = wosCountThru2011)) +
  geom_point(aes(color=journal), alpha =0.5) +
  geom_smooth(color="red")
p
```
###Using scales

```{r}
p <- ggplot(research, aes(x = log10(pdfDownloadsCount + 1),
                          y = log10(wosCountThru2011 + 1))) +
  geom_point(aes(color = journal)) +
  geom_smooth() +
  scale_x_continuous(breaks = c(1, 3), labels = c(10, 1000)) +
  scale_y_continuous(breaks = c(1, 3), labels = c(10, 1000),
  limits=c(1,3))
p
```

```{r}
p + scale_color_grey()
p + scale_color_manual(values = c("red", "yellow", "orange",
                                  "purple", "blue", "yellow",
                                  "pink"))
```

Update the plot to use a square root transformation instead of log10. Also color the points using the ColorBrewer palette “Accent”.

```{r}
p <- ggplot(research, aes(x = sqrt(pdfDownloadsCount),
                          y = sqrt(wosCountThru2011))) +
  geom_point(aes(color = journal)) +
  geom_smooth() + scale_color_brewer(palette = "Accent", labels = 1:7, name = "title")
p
```

###Using facets to make subplots

```{r}
p <- ggplot(research, aes(x = sqrt(pdfDownloadsCount),
                          y = sqrt(wosCountThru2011))) +
  geom_point(aes(color = journal)) +
  geom_smooth() + scale_color_brewer(palette = "Accent") + facet_wrap(~journal, ncol=2)
p
```
using facet_grid

```{r}
research <- mutate(research, immuno = grepl("Immunology", plosSubjectTags))
p + facet_grid(journal~immuno)
```

```{r}
p <- ggplot(research, aes(x = sqrt(pdfDownloadsCount),
                          y = sqrt(wosCountThru2011))) +
  geom_point(aes(color = journal)) +
  geom_smooth() + scale_color_brewer(palette = "Accent") + facet_grid(journal~immuno)
p
```

### Using different geoms

```{r}
p <- ggplot(research, aes(x = journal,
                          y = sqrt(wosCountThru2011))) +
  geom_boxplot()
p
```

making a bar plot

```{r}
tweets_per_journal <- research %>%
  group_by(journal) %>%
  summarize(num = n(),
            mean = mean(backtweetsCount),
            sem = sd(backtweetsCount) / sqrt(num))
tweets_per_journal
```

```{r}
tweets_bar <- ggplot(tweets_per_journal, aes(x = journal, y = mean)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), width = 0.1) +
  geom_text(aes(label = num), hjust = 0, vjust = -1)
tweets_bar
```

Modify the dplyr code above to calculate the mean, SEM, and sample size of the number of article tweets per journal and per year. Use facet_wrap to make a separate subplot per year.

Correct solution:
```{r}
tweets_per_journal <- research %>%
  group_by(journal, year) %>%
  summarize(num = n(),
            mean = mean(backtweetsCount),
            sem = sd(backtweetsCount) / sqrt(num))
tweets_per_journal
```

```{r}
tweets_bar <- ggplot(tweets_per_journal, aes(x = journal, y = mean)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), width = 0.1) +
  geom_text(aes(label = num), hjust = 0, vjust = -1) +
  facet_wrap(~year)
tweets_bar
```

Making a poit grpah
```{r}
tweets_bar <- ggplot(tweets_per_journal, aes(x = journal, y = mean)) +
  geom_point(stat = "identity") +
  geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), width = 0.1) +
  geom_text(aes(label = num), hjust = 0, vjust = -1) +
  facet_wrap(~year)
tweets_bar
```
### Customizing plot

```{r}
tweets_bar + labs(title="sdf", x= "asd", y="asd") + theme_minimal
tweets_bar
tweets_bar + theme_bw()
tweets_bar + theme_classic()
```

